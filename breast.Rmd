---
title: "Breast cancer"
author: "Mar Garcia-Aloy"
output: 
  html_document:
    toc: true
    number_sections: false
    toc_float: true
---

```{r startpoint, include = FALSE}
startpoint <- Sys.time()
```

# Descripción del ejemplo 

En este documento voy a aplicar los algoritmos DIABLO (del paquete `mixomics`), MFA (del paquete `FactorMineR`) y DIABLO (del paquete `mixOmics`) al conjunto de datos de demostración proporcionado por el algoritmo DIABLO del paquete `mixOmics`.  
Se trata de un conjutno de datos llamado `breast.TCGA` que contiene datos de la expresión o la abundancia de tres conjuntos de datos ómicos coincidentes: ARNm, ARNm y proteómica para 220 muestras de cáncer de mama (Basal, Her2, Luminal A). Los datos están dividos en 2 grupos llamados "training set" (n=150) y "test set" (n=70). Al conjunto de datos "test set" le falta el conjunto de datos de proteómica.


## Objetivo

El objetivo de este análisis de integración de datos ómicos es identificar una huella multiómica altamente correlacionada que discrimine los distintos subtipos de cáncer de mama “Basal”, “Her2” y “LumA”.  
Así pues, en primer lugar se va a proceder con la integración de los niveles de expresión de miRNA y mRNA y de la abundancia de proteínas mientras se intenta discriminar entre los subtipos de cáncer de mama con las muestras del grupo “training”, para luego predecir los subtipos en las muestras del grupo “test”.


# DIABLO (mixOmics)

```{r}
library(mixOmics)
data(breast.TCGA)
```

## Preparación de los datos

En primer lugar se extraen los datos ómicos del "training set" en un objeto llamado `X` y las categorías a las que pertenecen en el objeto `Y`.

```{r}
X <- list(mRNA = breast.TCGA$data.train$mrna, 
          miRNA = breast.TCGA$data.train$mirna, 
          protein = breast.TCGA$data.train$protein)
Y <- breast.TCGA$data.train$subtype
summary(Y)
```

## Número de variables a seleccionar por conjunto de datos y componente

```{r}
test.keepX = list(
  mrna = seq(10,40,20), mirna = seq(10,30,10), protein = seq(1,10,5))
set.seed(123)
tune = tune.block.splsda(
  X = X, Y = Y, ncomp = 2, test.keepX = test.keepX, 
  design = matrix(1, ncol = length(X), nrow = length(X), 
                  dimnames = list(names(X), names(X))), 
  nrepeat = 3)
tune$choice.keepX
tmp <- data.frame(tune$error.rate)
tmp[order(tmp$comp1, tmp$comp2),]
list.keepX <- list(mRNA = c(30, 30), miRNA = c(30, 30), protein = c(6,6))
```


## Ejecución del modelo

```{r}
res.diablo <- block.splsda(X = X, Y = Y, keepX = list.keepX, ncomp = 2, scale = TRUE, mode = "regression")
```

## Evaluación del modelo

### Capacidad de clasificar

```{r}
set.seed(123) # for reproducibility in this vignette
perf.diablo <- perf(res.diablo, validation = 'Mfold', folds = 5, 
                      nrepeat = 10, 
                      dist = 'centroids.dist')
perf.diablo$MajorityVote.error.rate
```

### AUC

```{r}
auroc(res.diablo, roc.block = "miRNA", roc.comp = 1)
auroc(res.diablo, roc.block = "miRNA", roc.comp = 2)
```

Parece ser que el primer componente consigue una buena separación de las muestras "Basal" y "LumA", pero no de las muestras "Her2", y auq el segundo componente consigue una buena separación de todas las 3 clases.

### Predicción usando un conjunto de muestras externas

```{r}
# prepare test set data: here one block (proteins) is missing
X.test <- list(mRNA = breast.TCGA$data.test$mrna, 
               miRNA = breast.TCGA$data.test$mirna)

predict.diablo <- predict(res.diablo, newdata = X.test)
confusion.mat <- get.confusion_matrix(
  truth = breast.TCGA$data.test$subtype, 
  predicted = predict.diablo$MajorityVote$centroids.dist[,2])
library(knitr)
kable(confusion.mat)
get.BER(confusion.mat)
```

En el conjunto de datos “test”, un “BER” del 16% estaría indicando una relativamente buena precisión de predicción para los subtipos de cáncer de mama.

## Muestras

```{r}
plotIndiv(res.diablo, blocks = "consensus", ellipse = TRUE, legend = TRUE)
```

En este caso, se observa como el primer componente separa principalmente las muestras "Basal" (azul) de las muestras "LumA" (gris), mientras que es el segundo componente separa las muestras "Her2" (naranja) del resto de muestras.

## Variables

```{r}
plotVar(res.diablo, 
        var.names = c(FALSE, FALSE, TRUE), 
        legend = TRUE, pch = c(16,16,1))
plotLoadings(res.diablo, comp = 1, contrib = "max")
plotLoadings(res.diablo, comp = 2, contrib = "max")
plotDiablo(res.diablo, ncomp = 1)
plotDiablo(res.diablo, ncomp = 2)
circosPlot(res.diablo, cutoff = 0.7)
jpeg(filename="breast_cim.jpeg")
cimDiablo(res.diablo, 
          color.blocks = c('darkorchid', 'brown1', 'lightgreen'), 
          comp = 1, margin = c(8,20), legend.position = "right")
dev.off()
network(res.diablo, blocks = c(1,2,3),
        color.node = c('darkorchid', 'brown1', 'lightgreen'), 
        cutoff = 0.7, save = 'jpeg', name.save = 'breast_network')
```
![](/Users/lenovo/Documents/GitHub/UOC_TFM_omicsintegration/breast_cim.jpeg)
![](/Users/lenovo/Documents/GitHub/UOC_TFM_omicsintegration/breast_network.jpeg)



# MFA (FactorMiner)

```{r}
library(FactoMineR)
library(factoextra)
library(kableExtra)
library(dplyr)
```

En este caso los datos deben situarse en un “data frame” y durante la ejecución del modelo se indican qué columnas pertenecen a cada conjunto de variables. Además, el algoritmo permite definir las variables como activas (aquellas que se usarán para la construcción del modelo) o suplementarias (aquellas que aportan información descriptiva/complementaria al “output” obtenido, pero que no se usan para la realización del modelo). En este caso, se van a usar todas las variables como activas, a excepción del tipo de cáncer, que se va ausar como variable suplementaria.

```{r}
breast1 <- data.frame(t(do.call("cbind", breast.TCGA[[1]])))
breast2 <- data.frame(t(do.call("cbind", breast.TCGA[[2]])))
breast <- merge(breast1, breast2, by = "row.names", all = TRUE)
rownames(breast) <- breast$Row.names
breast <- breast[,-1]
breast <- t(breast)
subtype <- breast[,"subtype"]
subtype <- factor(subtype, labels = c("Basal", "Her2", "LumA"))
tmp <- c(colnames(breast.TCGA$data.train$mirna),
         colnames(breast.TCGA$data.train$mrna),
         colnames(breast.TCGA$data.train$protein))
breast <- data.frame(breast[,match(tmp, colnames(breast))])
breast$subtype <- subtype

res.mfa <- MFA(breast, 
               group = c(ncol(breast.TCGA$data.train[[1]]), 
                         ncol(breast.TCGA$data.train[[2]]), 
                         ncol(breast.TCGA$data.train[[3]]), 1), 
               type = c(rep("s", 3), "n"),
               ncp = 4,
               name.group = names(breast.TCGA$data.train),
               num.group.sup = c(4),
               graph = FALSE)
```

## “Eigenvalues” / Varianzas

La proporción de las varianzas retenidas para cada una de las dimensiones es:

```{r}
res.mfa$eig[c(1:10, (nrow(res.mfa$eig)-2):nrow(res.mfa$eig)),] %>%
  kbl() %>%
  kable_minimal()
fviz_screeplot(res.mfa)
```

## Muestras

```{r}
plot(res.mfa, axes = c(1, 2), choix="ind", lab.ind=FALSE, habillage = "subtype")
plot(res.mfa, axes = c(3, 4), choix="ind", lab.ind=FALSE, habillage = "subtype")
```

En este caso se observa que entre las 4 primeras dimensiones, la única que consigue separar grupos es la primera, la cual separa las muestras "Basal" de las muestras "LumA".  


## Variables

### Variables agrupadas

```{r}
plot.MFA(res.mfa, choix="group", axes = 1:2)
fviz_contrib(res.mfa, "group", axes = 1)
```

En la primera dimensión (que es aquella que por ahora nos interesa, ya que es la única que parece ser capaz de separar 2 grupos), los grupos de variables `mrna` y `mirna` presentan un mayor peso respeto al grupo de variables `protein`. Esto, a lo mejor, podría estar relacionado con el hecho de que únicamente 2/3 partes del dataset (i.e., las muestras pertenecientes al "training set") presentan datos de proteínas.

### Variables individuales

```{r}
fviz_mfa_var(res.mfa, "quanti.var", axes = c(1, 2), palette = "jco", 
             col.var.sup = "violet", repel = TRUE,
             geom = "point", legend = "bottom")
fviz_contrib(res.mfa, choice = "quanti.var", axes = 1, top = 20,
             palette = "jco")
fviz_mfa_var(res.mfa, "quanti.var", axes = c(1, 2), palette = "jco", 
             repel = TRUE,
             geom = c("point", "text"), legend = "bottom", select.var = list(contrib = 20))
```


# MCIA (omicade4)

```{r}
library(omicade4)
```


El MCIA es aplicado a una lista de “data frames”, donde las muestras se situan en las columnas, siempre colocadas en el mismo orden. Así pues, tenemos que asegurarnos de que el orden de las columnas en todos los conjuntos de datos es el mismo antes de realizar el MCIA. El número de variables no tiene por qué ser el mismo. Otro aspecto a tener en cuenta es que este algoritmo no permite trabjar con valores "missing", por lo que en este caso tendremos que excluir los datos referentes a las proteínas, ya que estos no fueron medidos en todas las muestras.

```{r}
all(colnames(breast.TCGA$data.train$mirna)==colnames(breast.TCGA$data.test$mirna))
all(colnames(breast.TCGA$data.train$mrna)==colnames(breast.TCGA$data.test$mrna))
breast.list <- list(
  mirna <- t(rbind(breast.TCGA$data.train$mirna, breast.TCGA$data.test$mirna)),
  mrna <-  t(rbind(breast.TCGA$data.train$mrna, breast.TCGA$data.test$mrna))
)
sapply(breast.list, dim)
all(colnames(breast.list[[1]]) == colnames(breast.list[[2]]))

res.mcia <- mcia(breast.list, cia.nf = 4)
plot.mcia(res.mcia, axes=1:2, phenovec = subtype, df.color = c(4,6), 
          sample.lab=FALSE, gene.nlab = 2)
plot.mcia(res.mcia, axes=3:4, phenovec = subtype, df.color = c(4,6), 
          sample.lab=FALSE, gene.nlab = 2)
```

## “Eigenvalues” / Varianzas

```{r}
eig <- data.frame(
  eigenvalue = res.mcia$mcoa$pseudoeig,
  "percentage of variance" = res.mcia$mcoa$pseudoeig / 
    sum(res.mcia$mcoa$pseudoeig)*100,
  "cumulative percentage of variance" = NA)
for(i in 1:nrow(eig)){
  eig[i,3] <- sum(eig[1:i,2])
}
eig[c(1:10, (nrow(eig)-2):nrow(eig)),] %>%
  kbl() %>%
  kable_minimal()
barplot(eig[,2])
```

## Muestras

```{r}
par(mfrow=c(1,2))
plot(res.mcia$mcoa$SynVar$SynVar1, res.mcia$mcoa$SynVar$SynVar2, 
     col = seq(1:3)[subtype], pch = 16,
     xlab = paste0("Dim 1 (", round(eig[1,2], 2), "%)"),
     ylab = paste0("Dim 2 (", round(eig[2,2], 2), "%)"))
grid()
abline(v=0, lty = 2)
abline(h=0, lty = 2)
#legend("bottomright", col = c(seq(1:8), "purple"), 
#       legend = levels(cancer_type), pch = 16)

plot(res.mcia$mcoa$SynVar$SynVar3, res.mcia$mcoa$SynVar$SynVar4, 
     col = seq(1:3)[subtype], pch = 16,
     xlab = paste0("Dim 3 (", round(eig[3,2], 2), "%)"),
     ylab = paste0("Dim 4 (", round(eig[4,2], 2), "%)"))
grid()
abline(v=0, lty = 2)
abline(h=0, lty = 2)
```



Al igual como pasaba con el algoritmo MFA, el algoritmo es capaz de separar las muestras "Basal" de las muestras "LumA" en la primera dimensión, pero parece no serlo para discriminar las muestras "Her2", almenos cuando se evaluan las 4 primeras dimensiones.  

## Variables

### Variables agrupadas

```{r}
par(mfrow = c(1, 2))
plot(res.mcia$mcoa$cov2$cov21, res.mcia$mcoa$cov2$cov22, 
     xlim = c(0,max(max(res.mcia$mcoa$cov2$cov21))+0.1), 
     ylim = c(0,max(res.mcia$mcoa$cov2$cov22)+0.1), col = 1:4, pch=16,
     xlab = "pseudoeig 1", ylab = "pseudoeig 2")
grid()
abline(v=0, lty = 2)
abline(h=0, lty = 2)
text(res.mcia$mcoa$cov2$cov21, res.mcia$mcoa$cov2$cov22, 
     rownames(res.mcia$mcoa$cov2), pos = 1, col = 1:4, cex = 0.8)

plot(res.mcia$mcoa$cov2$cov23, res.mcia$mcoa$cov2$cov24, 
     xlim = c(0,max(max(res.mcia$mcoa$cov2$cov23))+0.1), 
     ylim = c(0,max(res.mcia$mcoa$cov2$cov24)+0.1), col = 1:4, pch=16,
     xlab = "pseudoeig 3", ylab = "pseudoeig 4")
grid()
abline(v=0, lty = 2)
abline(h=0, lty = 2)
text(res.mcia$mcoa$cov2$cov23, res.mcia$mcoa$cov2$cov24, 
     rownames(res.mcia$mcoa$cov2), pos = 1, col = 1:4, cex = 0.8)
```

### Variables individuales

```{r}
idx <- abs(res.mcia$mcoa$Tco$SV1) > 1
plot(res.mcia$mcoa$Tco$SV1, res.mcia$mcoa$Tco$SV2, 
     col = c(rep(4, nrow(breast.list[[1]])), 
             rep(6, nrow(breast.list[[2]]))), pch = 16,
     xlab = paste0("Dim 1 (", round(eig[1,2], 2), "%)"),
     ylab = paste0("Dim 2 (", round(eig[2,2], 2), "%)"),
     xlim = c((min(res.mcia$mcoa$Tco$SV1)-0.1), 
              (max(res.mcia$mcoa$Tco$SV1)+0.1)),
     ylim = c((min(res.mcia$mcoa$Tco$SV2)-0.1), 
              (max(res.mcia$mcoa$Tco$SV2)+0.1)))
grid()
abline(v=0, lty = 2)
abline(h=0, lty = 2)
text(res.mcia$mcoa$Tco$SV1[idx], 
     res.mcia$mcoa$Tco$SV2[idx], 
     gsub("\\..*", "", rownames(res.mcia$mcoa$axis)[idx]), 
     pos = 1, cex = 0.5)
```


# Conclusiones

- `DIABLO` y `MFA` permiten trabajar con datos "missing", mientras que `MCIA` no lo permite.  
- El algoritmo `DIABLO` permite la aplicación de métodos "sparse", mientras que los otros no.  
- Únicamente `DIABLO` es capaz de separar los 3 grupos (2 en la primera dimensión y el 3o en la segunda dimensión). Esto podría estar relacionado con el hecho de usar un método "sparse", ya que cuando no se usa este tipo de métodos, tampoco DIABLO es capaz de separar las 3 clases en ninguna de las 4 primeras dimensiones (data not shown).  

# Session information

```{r session}
Sys.time()-startpoint
devtools::session_info()
```
